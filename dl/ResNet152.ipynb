{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet152",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8ibhqoX2T7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1fd36c23-aa22-4cff-da07-815a4d30ab5f"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NakMB3oScqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "24a61c7d-428e-491f-a364-01d4f47f050e"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_vpjEkgVohi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d06e827-50ac-4d4c-e1ba-b508fda2530b"
      },
      "source": [
        "%%writefile download_df.py\n",
        "import os\n",
        "import kaggle\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "def download_df():\n",
        "    if not os.path.exists(\"data\"):\n",
        "        os.makedirs(\"data\")\n",
        "    k = kaggle.KaggleApi({\"username\": \"jdsz5paulina\", \"key\": \"5277445bf2e6cef9aac564d8f7c5b87d\"})\n",
        "    k.authenticate()\n",
        "    print(\"kaggle.com: authenticated\")\n",
        "    k.dataset_download_cli(\"grassknoted/asl-alphabet\", unzip=True, path=\"data\")\n",
        "    pat = \"data/asl_alphabet_test/asl_alphabet_test\"\n",
        "    onlyfiles = [f for f in listdir(pat) if isfile(join(pat, f))]\n",
        "    for o in onlyfiles:\n",
        "      new_dir = o.replace(\"_test.jpg\", \"\")\n",
        "      if not os.path.exists(f\"{pat}/{new_dir}\"):\n",
        "        os.makedirs(f\"{pat}/{new_dir}\")\n",
        "      os.rename(f\"{pat}/{o}\", f\"{pat}/{new_dir}/{o}\")\n",
        "if __name__ == \"__main__\":\n",
        "    download_df()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing download_df.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7nGrqfdV9u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  !mkdir ~/.kaggle\n",
        "except:\n",
        "  pass\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "api_token = {\"username\": \"jdsz5paulina\", \"key\": \"5277445bf2e6cef9aac564d8f7c5b87d\"}\n",
        "import json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydM43ripXFr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "cdd6a1de-e4a7-4fe9-a340-4176ff8175a5"
      },
      "source": [
        "!python download_df.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.com: authenticated\n",
            "Downloading asl-alphabet.zip to data\n",
            " 99% 1.02G/1.03G [00:18<00:00, 45.1MB/s]\n",
            "100% 1.03G/1.03G [00:19<00:00, 57.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujhosZYYweEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = 'data/asl_alphabet_train/asl_alphabet_train'\n",
        "test_dir = \"data/asl_alphabet_test/asl_alphabet_test\"\n",
        "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
        "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
        "                   'Z':25,'space':26,'del':27,'nothing':28}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQtWqdPowIMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    print(\"LOADING DATA FROM : \",end = \"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        print(folder, end = ' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n",
        "            temp_img = cv2.resize(temp_img, size)\n",
        "            images.append(temp_img)\n",
        "            labels.append(labels_dict[folder])\n",
        "    \n",
        "    images = np.array(images)\n",
        "    images = images.astype('float32')/255.0\n",
        "    \n",
        "    labels = keras.utils.to_categorical(labels)\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)\n",
        "    print()\n",
        "    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n",
        "    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n",
        "    \n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7NBVuNsx-RY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(model, x, y, callbacks_list ,eps=5):\n",
        "    model_hist = model.fit(x, y, batch_size = 200, epochs = eps, validation_split = 0.1, callbacks=callbacks_list)\n",
        "    return model_hist "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-Clw6bgwOTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(pretrained_model, all_character_names, IMG_SIZE, show_summary=True):\n",
        "    IN_SHAPE = (*IMG_SIZE, 3)\n",
        "    if pretrained_model == 'VGG16':\n",
        "        pretrained_model = keras.applications.VGG16(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'ResNet152':\n",
        "        pretrained_model = keras.applications.ResNet152(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'InceptionV3':\n",
        "        pretrained_model = keras.applications.InceptionV3(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'DenseNet121':\n",
        "        pretrained_model = keras.applications.DenseNet121(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'NASNetLarge':\n",
        "        pretrained_model = keras.applications.NASNetLarge(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'EfficientNetB3':\n",
        "        pretrained_model = keras.applications.EfficientNetB3(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'EfficientNetB7':\n",
        "        input = Input(shape=IN_SHAPE)\n",
        "        inception_model = keras.applications.EfficientNetB7(\n",
        "            include_top=False,\n",
        "            input_tensor=input,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "        \n",
        "        flattened_outputs = [Flatten()(inception_model.output),\n",
        "                             Flatten()(xception_model.output),\n",
        "                             Flatten()(resnet_model.output)]\n",
        "        output = Concatenate()(flattened_outputs)\n",
        "        pretrained_model = Model(input, output)\n",
        "    output = pretrained_model.output\n",
        "    # if pretrained_model.output.shape.ndims > 2:\n",
        "    #     output = Flatten()(output)\n",
        "    # else:\n",
        "    output = Flatten()(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Dropout(0.5)(output)\n",
        "    output = Dense(512, activation='relu')(output)\n",
        "        # output = BatchNormalization()(output)\n",
        "        # output = Dropout(0.5)(output)\n",
        "    output = Dense(all_character_names, activation='sigmoid')(output)\n",
        "    model = keras.models.Model(pretrained_model.input, output)\n",
        "    for layer in pretrained_model.layers:\n",
        "        layer.trainable = False\n",
        "    if show_summary:\n",
        "        model.summary(line_length=200)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Q0dkw0vTcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQj6TbLRlnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model, pat, name):\n",
        "  if not os.path.exists(pat):\n",
        "      os.makedirs(pat)\n",
        "  try:\n",
        "    model.save(f\"{pat}/{name}.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LyMxo0jryD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_charts(history, pat, name):\n",
        "  if not os.path.exists(pat):\n",
        "      os.makedirs(pat)\n",
        "  try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig(f\"{pat}/{name}.png\")\n",
        "    print(\"Saved chart to disk\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG1GtYQBaW-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil, pathlib, fnmatch\n",
        "\n",
        "def move_dir(src: str, dst: str, pattern: str = '*'):\n",
        "    if not os.path.isdir(dst):\n",
        "        pathlib.Path(dst).mkdir(parents=True, exist_ok=True)\n",
        "    for f in fnmatch.filter(os.listdir(src), pattern):\n",
        "        shutil.move(os.path.join(src, f), os.path.join(dst, f))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzWVWK64zOsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iter_models(pretrained_model_list):\n",
        "  for pm, size, epochs in pretrained_model_list:\n",
        "    try:\n",
        "      print(f\"fitting: {pm} in size: {size}\")\n",
        "      name = f\"model={pm}_size={size}_epochs={epochs}\"\n",
        "      disk_path = \"/content/gdrive/My Drive/dl_project\"\n",
        "      trained_model = Path(f\"{disk_path}/models/{pm}/{name}.h5\")\n",
        "\n",
        "      if not os.path.exists(f\"{disk_path}/models/{pm}\"):\n",
        "          os.makedirs(f\"{disk_path}/models/{pm}\")\n",
        "      if not os.path.exists(f\"{disk_path}/models/{pm}/logs\"):\n",
        "          os.makedirs(f\"{disk_path}/models/{pm}/logs\")\n",
        "      if trained_model.is_file():\n",
        "          continue\n",
        "\n",
        "      X_train, X_test, Y_train, Y_test = load_data(size=size)\n",
        "      mod = get_model(pm, 29, size, show_summary=False)\n",
        "      model_checkpoint_name = \"{epoch:02d}-{accuracy:.2f}.h5\"\n",
        "      checkpoint = ModelCheckpoint(f\"{disk_path}/models/{pm}/{pm}-{model_checkpoint_name}\", monitor='accuracy', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "      callbacks_list = [\n",
        "        checkpoint,\n",
        "        TensorBoard(log_dir=\"logs\"),\n",
        "      ]\n",
        "      history = fit_model(mod, X_train, Y_train, callbacks_list, eps=epochs)\n",
        "      save_model(mod, f\"{disk_path}/models/{pm}\", name)\n",
        "      save_charts(history, f\"{disk_path}/models/{pm}/charts\", name)\n",
        "      try:\n",
        "        move_dir(\"logs\", f\"{disk_path}/models/{pm}/logs\")\n",
        "        import gc\n",
        "        gc.collect()\n",
        "      except Exception as ex:\n",
        "        print(ex)\n",
        "    except Exception as e:\n",
        "      print(e)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sNIOYo0TTkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "22533966-8a33-4a29-9393-6ede7644a1eb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 30 08:07:52 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PE1L9iML-3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c0317e1-b561-4cf7-d2d3-1532550d1d92"
      },
      "source": [
        "  pretrained_model_list = [\n",
        "                           # ('VGG16', (71, 71), 12),\n",
        "                           ('ResNet152', (71, 71), 12),\n",
        "                           # ('InceptionV3', (71, 71), 12),\n",
        "                           # ('DenseNet121', (71, 71), 12),\n",
        "                           # ('NASNetLarge', (71, 71), 12)\n",
        "                           # ('EfficientNetB3', (71, 71), 12)\n",
        "                           # ('EfficientNetB7', (71, 71), 12)\n",
        "                           ]\n",
        "iter_models(pretrained_model_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting: ResNet152 in size: (71, 71)\n",
            "LOADING DATA FROM : B | K | I | Y | M | R | E | Z | L | del | P | N | nothing | U | X | H | V | W | J | O | Q | space | G | S | A | T | F | C | D | \n",
            "Loaded 82650 images for training, Train data shape = (82650, 71, 71, 3)\n",
            "Loaded 4350 images for testing Test data shape = (4350, 71, 71, 3)\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234700800/234698864 [==============================] - 17s 0us/step\n",
            "Train on 74385 samples, validate on 8265 samples\n",
            "Epoch 1/12\n",
            "74385/74385 [==============================] - 418s 6ms/step - loss: 0.5676 - accuracy: 0.8690 - val_loss: 8.5243 - val_accuracy: 0.0391\n",
            "\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-01-0.87.h5\n",
            "Epoch 2/12\n",
            "74385/74385 [==============================] - 396s 5ms/step - loss: 0.1927 - accuracy: 0.9600 - val_loss: 13.1226 - val_accuracy: 0.0347\n",
            "\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-02-0.96.h5\n",
            "Epoch 3/12\n",
            "74385/74385 [==============================] - 396s 5ms/step - loss: 0.1575 - accuracy: 0.9693 - val_loss: 11.5309 - val_accuracy: 0.0347\n",
            "\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-03-0.97.h5\n",
            "Epoch 4/12\n",
            "74385/74385 [==============================] - 396s 5ms/step - loss: 0.1280 - accuracy: 0.9735 - val_loss: 14.4914 - val_accuracy: 0.0347\n",
            "\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-04-0.97.h5\n",
            "Epoch 5/12\n",
            "74385/74385 [==============================] - 397s 5ms/step - loss: 0.0933 - accuracy: 0.9215 - val_loss: 1.1921e-07 - val_accuracy: 0.0353\n",
            "\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-05-0.92.h5\n",
            "Epoch 6/12\n",
            "74385/74385 [==============================] - 396s 5ms/step - loss: 1.1921e-07 - accuracy: 0.0344 - val_loss: 1.1921e-07 - val_accuracy: 0.0353\n",
            "\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-06-0.03.h5\n",
            "Epoch 7/12\n",
            "74385/74385 [==============================] - 396s 5ms/step - loss: 1.1921e-07 - accuracy: 0.0344 - val_loss: 1.1921e-07 - val_accuracy: 0.0353\n",
            "\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-07-0.03.h5\n",
            "Epoch 8/12\n",
            "74385/74385 [==============================] - 396s 5ms/step - loss: 1.1921e-07 - accuracy: 0.0344 - val_loss: 1.1921e-07 - val_accuracy: 0.0353\n",
            "\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-08-0.03.h5\n",
            "Epoch 9/12\n",
            "74385/74385 [==============================] - 397s 5ms/step - loss: 1.1921e-07 - accuracy: 0.0344 - val_loss: 1.1921e-07 - val_accuracy: 0.0353\n",
            "\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-09-0.03.h5\n",
            "Epoch 10/12\n",
            "74385/74385 [==============================] - 396s 5ms/step - loss: 1.1921e-07 - accuracy: 0.0344 - val_loss: 1.1921e-07 - val_accuracy: 0.0353\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-10-0.03.h5\n",
            "Epoch 11/12\n",
            "74385/74385 [==============================] - 397s 5ms/step - loss: 1.1921e-07 - accuracy: 0.0344 - val_loss: 1.1921e-07 - val_accuracy: 0.0353\n",
            "\n",
            "Epoch 00011: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-11-0.03.h5\n",
            "Epoch 12/12\n",
            "74385/74385 [==============================] - 397s 5ms/step - loss: 1.1921e-07 - accuracy: 0.0344 - val_loss: 1.1921e-07 - val_accuracy: 0.0353\n",
            "\n",
            "Epoch 00012: saving model to /content/gdrive/My Drive/dl_project/models/ResNet152/ResNet152-12-0.03.h5\n",
            "Saved model to disk\n",
            "Saved chart to disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqGhv8Cd7cPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08e369a4-2f0a-45c9-f44d-d82163d84e70"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting: ResNet152 in size: (71, 71)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}