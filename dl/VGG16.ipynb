{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8ibhqoX2T7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "625e1bb5-a3cd-46c7-9acf-dd62d5aba965"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NakMB3oScqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e7cfd82-b7c5-4c9a-eacf-2437d3a745e8"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_vpjEkgVohi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2894d8aa-e0b8-41c0-aeb9-fbe7ea9beaba"
      },
      "source": [
        "%%writefile download_df.py\n",
        "import os\n",
        "import kaggle\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "def download_df():\n",
        "    if not os.path.exists(\"data\"):\n",
        "        os.makedirs(\"data\")\n",
        "    k = kaggle.KaggleApi({\"username\": \"jdsz5paulina\", \"key\": \"5277445bf2e6cef9aac564d8f7c5b87d\"})\n",
        "    k.authenticate()\n",
        "    print(\"kaggle.com: authenticated\")\n",
        "    k.dataset_download_cli(\"grassknoted/asl-alphabet\", unzip=True, path=\"data\")\n",
        "    pat = \"data/asl_alphabet_test/asl_alphabet_test\"\n",
        "    onlyfiles = [f for f in listdir(pat) if isfile(join(pat, f))]\n",
        "    for o in onlyfiles:\n",
        "      new_dir = o.replace(\"_test.jpg\", \"\")\n",
        "      if not os.path.exists(f\"{pat}/{new_dir}\"):\n",
        "        os.makedirs(f\"{pat}/{new_dir}\")\n",
        "      os.rename(f\"{pat}/{o}\", f\"{pat}/{new_dir}/{o}\")\n",
        "if __name__ == \"__main__\":\n",
        "    download_df()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting download_df.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7nGrqfdV9u0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02320655-b378-4f2c-accb-d6f4a0e9caf6"
      },
      "source": [
        "try:\n",
        "  !mkdir ~/.kaggle\n",
        "except:\n",
        "  pass\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "api_token = {\"username\": \"jdsz5paulina\", \"key\": \"5277445bf2e6cef9aac564d8f7c5b87d\"}\n",
        "import json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydM43ripXFr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "eecb08fb-0f5c-45ef-8c5d-1296cbc692b5"
      },
      "source": [
        "!python download_df.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.com: authenticated\n",
            "Downloading asl-alphabet.zip to data\n",
            " 99% 1.02G/1.03G [00:10<00:00, 142MB/s]\n",
            "100% 1.03G/1.03G [00:10<00:00, 109MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujhosZYYweEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = 'data/asl_alphabet_train/asl_alphabet_train'\n",
        "test_dir = \"data/asl_alphabet_test/asl_alphabet_test\"\n",
        "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
        "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
        "                   'Z':25,'space':26,'del':27,'nothing':28}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQtWqdPowIMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    print(\"LOADING DATA FROM : \",end = \"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        print(folder, end = ' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n",
        "            temp_img = cv2.resize(temp_img, size)\n",
        "            images.append(temp_img)\n",
        "            labels.append(labels_dict[folder])\n",
        "    \n",
        "    images = np.array(images)\n",
        "    images = images.astype('float32')/255.0\n",
        "    \n",
        "    labels = keras.utils.to_categorical(labels)\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)\n",
        "    print()\n",
        "    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n",
        "    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n",
        "    \n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7NBVuNsx-RY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(model, x, y, callbacks_list ,eps=5):\n",
        "    model_hist = model.fit(x, y, batch_size = 200, epochs = eps, validation_split = 0.1, callbacks=callbacks_list)\n",
        "    return model_hist "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-Clw6bgwOTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(pretrained_model, all_character_names, IMG_SIZE, show_summary=True):\n",
        "    IN_SHAPE = (*IMG_SIZE, 3)\n",
        "    if pretrained_model == 'VGG16':\n",
        "        pretrained_model = keras.applications.VGG16(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'ResNet152':\n",
        "        pretrained_model = keras.applications.ResNet152(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'InceptionV3':\n",
        "        pretrained_model = keras.applications.InceptionV3(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'DenseNet121':\n",
        "        pretrained_model = keras.applications.DenseNet121(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'NASNetLarge':\n",
        "        pretrained_model = keras.applications.NASNetLarge(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'EfficientNetB3':\n",
        "        pretrained_model = keras.applications.EfficientNetB3(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'EfficientNetB7':\n",
        "        input = Input(shape=IN_SHAPE)\n",
        "        inception_model = keras.applications.EfficientNetB7(\n",
        "            include_top=False,\n",
        "            input_tensor=input,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "        \n",
        "        flattened_outputs = [Flatten()(inception_model.output),\n",
        "                             Flatten()(xception_model.output),\n",
        "                             Flatten()(resnet_model.output)]\n",
        "        output = Concatenate()(flattened_outputs)\n",
        "        pretrained_model = Model(input, output)\n",
        "    output = pretrained_model.output\n",
        "    # if pretrained_model.output.shape.ndims > 2:\n",
        "    #     output = Flatten()(output)\n",
        "    # else:\n",
        "    output = Flatten()(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Dropout(0.5)(output)\n",
        "    output = Dense(512, activation='relu')(output)\n",
        "        # output = BatchNormalization()(output)\n",
        "        # output = Dropout(0.5)(output)\n",
        "    output = Dense(all_character_names, activation='sigmoid')(output)\n",
        "    model = keras.models.Model(pretrained_model.input, output)\n",
        "    for layer in pretrained_model.layers:\n",
        "        layer.trainable = False\n",
        "    if show_summary:\n",
        "        model.summary(line_length=200)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Q0dkw0vTcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQj6TbLRlnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model, pat, name):\n",
        "  if not os.path.exists(pat):\n",
        "      os.makedirs(pat)\n",
        "  try:\n",
        "    model.save(f\"{pat}/{name}.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LyMxo0jryD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_charts(history, pat, name):\n",
        "  if not os.path.exists(pat):\n",
        "      os.makedirs(pat)\n",
        "  try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig(f\"{pat}/{name}.png\")\n",
        "    print(\"Saved chart to disk\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG1GtYQBaW-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil, pathlib, fnmatch\n",
        "\n",
        "def move_dir(src: str, dst: str, pattern: str = '*'):\n",
        "    if not os.path.isdir(dst):\n",
        "        pathlib.Path(dst).mkdir(parents=True, exist_ok=True)\n",
        "    for f in fnmatch.filter(os.listdir(src), pattern):\n",
        "        shutil.move(os.path.join(src, f), os.path.join(dst, f))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzWVWK64zOsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iter_models(pretrained_model_list):\n",
        "  for pm, size, epochs in pretrained_model_list:\n",
        "    try:\n",
        "      print(f\"fitting: {pm} in size: {size}\")\n",
        "      name = f\"model={pm}_size={size}_epochs={epochs}\"\n",
        "      disk_path = \"/content/gdrive/My Drive/dl_project\"\n",
        "      trained_model = Path(f\"{disk_path}/models/{pm}/{name}.h5\")\n",
        "\n",
        "      if not os.path.exists(f\"{disk_path}/models/{pm}\"):\n",
        "          os.makedirs(f\"{disk_path}/models/{pm}\")\n",
        "      if not os.path.exists(f\"{disk_path}/models/{pm}/logs\"):\n",
        "          os.makedirs(f\"{disk_path}/models/{pm}/logs\")\n",
        "      if trained_model.is_file():\n",
        "          continue\n",
        "\n",
        "      X_train, X_test, Y_train, Y_test = load_data(size=size)\n",
        "      mod = get_model(pm, 29, size, show_summary=False)\n",
        "      model_checkpoint_name = \"{epoch:02d}-{accuracy:.2f}.h5\"\n",
        "      checkpoint = ModelCheckpoint(f\"{disk_path}/models/{pm}/{pm}-{model_checkpoint_name}\", monitor='accuracy', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "      callbacks_list = [\n",
        "        checkpoint,\n",
        "        TensorBoard(log_dir=\"logs\"),\n",
        "      ]\n",
        "      history = fit_model(mod, X_train, Y_train, callbacks_list, eps=epochs)\n",
        "      save_model(mod, f\"{disk_path}/models/{pm}\", name)\n",
        "      save_charts(history, f\"{disk_path}/models/{pm}/charts\", name)\n",
        "      try:\n",
        "        move_dir(\"logs\", f\"{disk_path}/models/{pm}/logs\")\n",
        "        import gc\n",
        "        gc.collect()\n",
        "      except Exception as ex:\n",
        "        print(ex)\n",
        "    except Exception as e:\n",
        "      print(e)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sNIOYo0TTkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ec3a7a7f-8c7d-4b9b-8ebe-3f27879f47c3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 29 14:14:28 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PE1L9iML-3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b474339c-a7e4-4a74-bb00-1e493a37c69d"
      },
      "source": [
        "  pretrained_model_list = [\n",
        "                           ('VGG16', (71, 71), 12),\n",
        "                           # ('ResNet152', (71, 71), 12),\n",
        "                           # ('InceptionV3', (71, 71), 12),\n",
        "                           # ('DenseNet121', (71, 71), 12),\n",
        "                           # ('NASNetLarge', (71, 71), 12)\n",
        "                           # ('EfficientNetB3', (71, 71), 12)\n",
        "                           # ('EfficientNetB7', (71, 71), 12)\n",
        "                           ]\n",
        "iter_models(pretrained_model_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting: VGG16 in size: (71, 71)\n",
            "LOADING DATA FROM : B | K | I | Y | M | R | E | Z | L | del | P | N | nothing | U | X | H | V | W | J | O | Q | space | G | S | A | T | F | C | D | \n",
            "Loaded 82650 images for training, Train data shape = (82650, 71, 71, 3)\n",
            "Loaded 4350 images for testing Test data shape = (4350, 71, 71, 3)\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 3s 0us/step\n",
            "Train on 74385 samples, validate on 8265 samples\n",
            "Epoch 1/12\n",
            "74385/74385 [==============================] - 130s 2ms/step - loss: 0.4041 - accuracy: 0.8849 - val_loss: 0.0861 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-01-0.88.h5\n",
            "Epoch 2/12\n",
            "74385/74385 [==============================] - 116s 2ms/step - loss: 0.1005 - accuracy: 0.9670 - val_loss: 0.0171 - val_accuracy: 0.9972\n",
            "\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-02-0.97.h5\n",
            "Epoch 3/12\n",
            "74385/74385 [==============================] - 116s 2ms/step - loss: 0.0726 - accuracy: 0.9763 - val_loss: 0.0100 - val_accuracy: 0.9984\n",
            "\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-03-0.98.h5\n",
            "Epoch 4/12\n",
            "74385/74385 [==============================] - 115s 2ms/step - loss: 0.0585 - accuracy: 0.9807 - val_loss: 0.0134 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-04-0.98.h5\n",
            "Epoch 5/12\n",
            "74385/74385 [==============================] - 115s 2ms/step - loss: 0.0522 - accuracy: 0.9823 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
            "\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-05-0.98.h5\n",
            "Epoch 6/12\n",
            "74385/74385 [==============================] - 115s 2ms/step - loss: 0.0447 - accuracy: 0.9853 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
            "\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-06-0.99.h5\n",
            "Epoch 7/12\n",
            "74385/74385 [==============================] - 116s 2ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-07-0.99.h5\n",
            "Epoch 8/12\n",
            "74385/74385 [==============================] - 115s 2ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-08-0.99.h5\n",
            "Epoch 9/12\n",
            "74385/74385 [==============================] - 115s 2ms/step - loss: 0.0359 - accuracy: 0.9883 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-09-0.99.h5\n",
            "Epoch 10/12\n",
            "74385/74385 [==============================] - 116s 2ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-10-0.99.h5\n",
            "Epoch 11/12\n",
            "74385/74385 [==============================] - 116s 2ms/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00011: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-11-0.99.h5\n",
            "Epoch 12/12\n",
            "74385/74385 [==============================] - 116s 2ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00012: saving model to /content/gdrive/My Drive/dl_project/models/VGG16/VGG16-12-0.99.h5\n",
            "Saved model to disk\n",
            "Saved chart to disk\n",
            "fitting: ResNet152 in size: (71, 71)\n",
            "LOADING DATA FROM : B | K | I | Y | M | R | E | Z | L | del | P | N | nothing | U | X | H | V | W | J | O | Q | space | G | S | A | T | F | C | D | "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqGhv8Cd7cPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  ResNet152 = [('ResNet152', (71, 71), 12)]\n",
        "                          \n",
        "iter_models(ResNet152)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}