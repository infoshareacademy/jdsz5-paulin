{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet121",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8ibhqoX2T7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3f3d2f12-6e12-4f9a-e40f-78ee2552aa7e"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NakMB3oScqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8691be7c-47ae-45cf-e598-df7fdea0665d"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_vpjEkgVohi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76b418e3-da39-4248-a0d4-58a3820a07b6"
      },
      "source": [
        "%%writefile download_df.py\n",
        "import os\n",
        "import kaggle\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "def download_df():\n",
        "    if not os.path.exists(\"data\"):\n",
        "        os.makedirs(\"data\")\n",
        "    k = kaggle.KaggleApi({\"username\": \"jdsz5paulina\", \"key\": \"5277445bf2e6cef9aac564d8f7c5b87d\"})\n",
        "    k.authenticate()\n",
        "    print(\"kaggle.com: authenticated\")\n",
        "    k.dataset_download_cli(\"grassknoted/asl-alphabet\", unzip=True, path=\"data\")\n",
        "    pat = \"data/asl_alphabet_test/asl_alphabet_test\"\n",
        "    onlyfiles = [f for f in listdir(pat) if isfile(join(pat, f))]\n",
        "    for o in onlyfiles:\n",
        "      new_dir = o.replace(\"_test.jpg\", \"\")\n",
        "      if not os.path.exists(f\"{pat}/{new_dir}\"):\n",
        "        os.makedirs(f\"{pat}/{new_dir}\")\n",
        "      os.rename(f\"{pat}/{o}\", f\"{pat}/{new_dir}/{o}\")\n",
        "if __name__ == \"__main__\":\n",
        "    download_df()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing download_df.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7nGrqfdV9u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  !mkdir ~/.kaggle\n",
        "except:\n",
        "  pass\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "api_token = {\"username\": \"jdsz5paulina\", \"key\": \"5277445bf2e6cef9aac564d8f7c5b87d\"}\n",
        "import json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydM43ripXFr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0accb991-da4b-4090-db8b-adaf0f6d1fe6"
      },
      "source": [
        "!python download_df.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.com: authenticated\n",
            "Downloading asl-alphabet.zip to data\n",
            "100% 1.02G/1.03G [00:10<00:00, 95.7MB/s]\n",
            "100% 1.03G/1.03G [00:10<00:00, 104MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujhosZYYweEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = 'data/asl_alphabet_train/asl_alphabet_train'\n",
        "test_dir = \"data/asl_alphabet_test/asl_alphabet_test\"\n",
        "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
        "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
        "                   'Z':25,'space':26,'del':27,'nothing':28}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQtWqdPowIMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    print(\"LOADING DATA FROM : \",end = \"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        print(folder, end = ' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n",
        "            temp_img = cv2.resize(temp_img, size)\n",
        "            images.append(temp_img)\n",
        "            labels.append(labels_dict[folder])\n",
        "    \n",
        "    images = np.array(images)\n",
        "    images = images.astype('float32')/255.0\n",
        "    \n",
        "    labels = keras.utils.to_categorical(labels)\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)\n",
        "    print()\n",
        "    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n",
        "    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n",
        "    \n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7NBVuNsx-RY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(model, x, y, callbacks_list ,eps=5):\n",
        "    model_hist = model.fit(x, y, batch_size = 200, epochs = eps, validation_split = 0.1, callbacks=callbacks_list)\n",
        "    return model_hist "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-Clw6bgwOTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(pretrained_model, all_character_names, IMG_SIZE, show_summary=True):\n",
        "    IN_SHAPE = (*IMG_SIZE, 3)\n",
        "    if pretrained_model == 'VGG16':\n",
        "        pretrained_model = keras.applications.VGG16(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'ResNet152':\n",
        "        pretrained_model = keras.applications.ResNet152(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'InceptionV3':\n",
        "        pretrained_model = keras.applications.InceptionV3(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'DenseNet121':\n",
        "        pretrained_model = keras.applications.DenseNet121(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'NASNetLarge':\n",
        "        pretrained_model = keras.applications.NASNetLarge(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'EfficientNetB3':\n",
        "        pretrained_model = keras.applications.EfficientNetB3(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'EfficientNetB7':\n",
        "        input = Input(shape=IN_SHAPE)\n",
        "        inception_model = keras.applications.EfficientNetB7(\n",
        "            include_top=False,\n",
        "            input_tensor=input,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "        \n",
        "        flattened_outputs = [Flatten()(inception_model.output),\n",
        "                             Flatten()(xception_model.output),\n",
        "                             Flatten()(resnet_model.output)]\n",
        "        output = Concatenate()(flattened_outputs)\n",
        "        pretrained_model = Model(input, output)\n",
        "    output = pretrained_model.output\n",
        "    # if pretrained_model.output.shape.ndims > 2:\n",
        "    #     output = Flatten()(output)\n",
        "    # else:\n",
        "    output = Flatten()(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Dropout(0.5)(output)\n",
        "    output = Dense(512, activation='relu')(output)\n",
        "        # output = BatchNormalization()(output)\n",
        "        # output = Dropout(0.5)(output)\n",
        "    output = Dense(all_character_names, activation='sigmoid')(output)\n",
        "    model = keras.models.Model(pretrained_model.input, output)\n",
        "    for layer in pretrained_model.layers:\n",
        "        layer.trainable = False\n",
        "    if show_summary:\n",
        "        model.summary(line_length=200)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Q0dkw0vTcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQj6TbLRlnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model, pat, name):\n",
        "  if not os.path.exists(pat):\n",
        "      os.makedirs(pat)\n",
        "  try:\n",
        "    model.save(f\"{pat}/{name}.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LyMxo0jryD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_charts(history, pat, name):\n",
        "  if not os.path.exists(pat):\n",
        "      os.makedirs(pat)\n",
        "  try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig(f\"{pat}/{name}.png\")\n",
        "    print(\"Saved chart to disk\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG1GtYQBaW-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil, pathlib, fnmatch\n",
        "\n",
        "def move_dir(src: str, dst: str, pattern: str = '*'):\n",
        "    if not os.path.isdir(dst):\n",
        "        pathlib.Path(dst).mkdir(parents=True, exist_ok=True)\n",
        "    for f in fnmatch.filter(os.listdir(src), pattern):\n",
        "        shutil.move(os.path.join(src, f), os.path.join(dst, f))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzWVWK64zOsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iter_models(pretrained_model_list):\n",
        "  for pm, size, epochs in pretrained_model_list:\n",
        "    try:\n",
        "      print(f\"fitting: {pm} in size: {size}\")\n",
        "      name = f\"model={pm}_size={size}_epochs={epochs}\"\n",
        "      disk_path = \"/content/gdrive/My Drive/dl_project\"\n",
        "      trained_model = Path(f\"{disk_path}/models/{pm}/{name}.h5\")\n",
        "\n",
        "      if not os.path.exists(f\"{disk_path}/models/{pm}\"):\n",
        "          os.makedirs(f\"{disk_path}/models/{pm}\")\n",
        "      if not os.path.exists(f\"{disk_path}/models/{pm}/logs\"):\n",
        "          os.makedirs(f\"{disk_path}/models/{pm}/logs\")\n",
        "      if trained_model.is_file():\n",
        "          continue\n",
        "\n",
        "      X_train, X_test, Y_train, Y_test = load_data(size=size)\n",
        "      mod = get_model(pm, 29, size, show_summary=False)\n",
        "      model_checkpoint_name = \"{epoch:02d}-{accuracy:.2f}.h5\"\n",
        "      checkpoint = ModelCheckpoint(f\"{disk_path}/models/{pm}/{pm}-{model_checkpoint_name}\", monitor='accuracy', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "      callbacks_list = [\n",
        "        checkpoint,\n",
        "        TensorBoard(log_dir=\"logs\"),\n",
        "      ]\n",
        "      history = fit_model(mod, X_train, Y_train, callbacks_list, eps=epochs)\n",
        "      save_model(mod, f\"{disk_path}/models/{pm}\", name)\n",
        "      save_charts(history, f\"{disk_path}/models/{pm}/charts\", name)\n",
        "      try:\n",
        "        move_dir(\"logs\", f\"{disk_path}/models/{pm}/logs\")\n",
        "        import gc\n",
        "        gc.collect()\n",
        "      except Exception as ex:\n",
        "        print(ex)\n",
        "    except Exception as e:\n",
        "      print(e)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sNIOYo0TTkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "2772ceb0-47d8-4e0d-c1f7-96511a7b4f2c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 30 10:03:27 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PE1L9iML-3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "944ceda5-618b-49c5-bb2b-ee5d30b317cf"
      },
      "source": [
        "  pretrained_model_list = [\n",
        "                           # ('VGG16', (71, 71), 12),\n",
        "                           # ('ResNet152', (71, 71), 12),\n",
        "                           # ('InceptionV3', (71, 71), 12),\n",
        "                           ('DenseNet121', (71, 71), 12),\n",
        "                           # ('NASNetLarge', (71, 71), 12)\n",
        "                           # ('EfficientNetB3', (71, 71), 12)\n",
        "                           # ('EfficientNetB7', (71, 71), 12)\n",
        "                           ]\n",
        "iter_models(pretrained_model_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting: DenseNet121 in size: (71, 71)\n",
            "LOADING DATA FROM : B | K | I | Y | M | R | E | Z | L | del | P | N | nothing | U | X | H | V | W | J | O | Q | space | G | S | A | T | F | C | D | \n",
            "Loaded 82650 images for training, Train data shape = (82650, 71, 71, 3)\n",
            "Loaded 4350 images for testing Test data shape = (4350, 71, 71, 3)\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "Train on 74385 samples, validate on 8265 samples\n",
            "Epoch 1/12\n",
            "74385/74385 [==============================] - 154s 2ms/step - loss: 0.4217 - accuracy: 0.8802 - val_loss: 3.6675 - val_accuracy: 0.3250\n",
            "\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-01-0.88.h5\n",
            "Epoch 2/12\n",
            "74385/74385 [==============================] - 135s 2ms/step - loss: 0.1009 - accuracy: 0.9668 - val_loss: 3.5023 - val_accuracy: 0.4076\n",
            "\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-02-0.97.h5\n",
            "Epoch 3/12\n",
            "74385/74385 [==============================] - 135s 2ms/step - loss: 0.0721 - accuracy: 0.9762 - val_loss: 4.7133 - val_accuracy: 0.3612\n",
            "\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-03-0.98.h5\n",
            "Epoch 4/12\n",
            "74385/74385 [==============================] - 134s 2ms/step - loss: 0.0594 - accuracy: 0.9806 - val_loss: 5.2658 - val_accuracy: 0.3607\n",
            "\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-04-0.98.h5\n",
            "Epoch 5/12\n",
            "74385/74385 [==============================] - 135s 2ms/step - loss: 0.0458 - accuracy: 0.9855 - val_loss: 4.9332 - val_accuracy: 0.3869\n",
            "\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-05-0.99.h5\n",
            "Epoch 6/12\n",
            "74385/74385 [==============================] - 135s 2ms/step - loss: 0.0383 - accuracy: 0.9873 - val_loss: 4.2461 - val_accuracy: 0.4240\n",
            "\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-06-0.99.h5\n",
            "Epoch 7/12\n",
            "74385/74385 [==============================] - 135s 2ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 4.5623 - val_accuracy: 0.4091\n",
            "\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-07-0.99.h5\n",
            "Epoch 8/12\n",
            "74385/74385 [==============================] - 134s 2ms/step - loss: 0.0373 - accuracy: 0.9880 - val_loss: 4.6708 - val_accuracy: 0.4115\n",
            "\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-08-0.99.h5\n",
            "Epoch 9/12\n",
            "74385/74385 [==============================] - 134s 2ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 4.9500 - val_accuracy: 0.3976\n",
            "\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-09-0.99.h5\n",
            "Epoch 10/12\n",
            "74385/74385 [==============================] - 134s 2ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 4.7734 - val_accuracy: 0.3924\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-10-0.99.h5\n",
            "Epoch 11/12\n",
            "74385/74385 [==============================] - 134s 2ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 4.9282 - val_accuracy: 0.4022\n",
            "\n",
            "Epoch 00011: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-11-0.99.h5\n",
            "Epoch 12/12\n",
            "74385/74385 [==============================] - 134s 2ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 4.6306 - val_accuracy: 0.4221\n",
            "\n",
            "Epoch 00012: saving model to /content/gdrive/My Drive/dl_project/models/DenseNet121/DenseNet121-12-0.99.h5\n",
            "Saved model to disk\n",
            "Saved chart to disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqGhv8Cd7cPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}