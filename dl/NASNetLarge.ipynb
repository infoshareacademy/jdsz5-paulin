{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NASNetLarge",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8ibhqoX2T7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8996072d-36c1-4311-8346-802377e5e482"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NakMB3oScqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbbf00d9-d8ab-4284-d249-9dc2fa7e2fa8"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_vpjEkgVohi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d5d2fb2-43a4-4dfd-baff-44492d38eb56"
      },
      "source": [
        "%%writefile download_df.py\n",
        "import os\n",
        "import kaggle\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "def download_df():\n",
        "    if not os.path.exists(\"data\"):\n",
        "        os.makedirs(\"data\")\n",
        "    k = kaggle.KaggleApi({\"username\": \"jdsz5paulina\", \"key\": \"5277445bf2e6cef9aac564d8f7c5b87d\"})\n",
        "    k.authenticate()\n",
        "    print(\"kaggle.com: authenticated\")\n",
        "    k.dataset_download_cli(\"grassknoted/asl-alphabet\", unzip=True, path=\"data\")\n",
        "    pat = \"data/asl_alphabet_test/asl_alphabet_test\"\n",
        "    onlyfiles = [f for f in listdir(pat) if isfile(join(pat, f))]\n",
        "    for o in onlyfiles:\n",
        "      new_dir = o.replace(\"_test.jpg\", \"\")\n",
        "      if not os.path.exists(f\"{pat}/{new_dir}\"):\n",
        "        os.makedirs(f\"{pat}/{new_dir}\")\n",
        "      os.rename(f\"{pat}/{o}\", f\"{pat}/{new_dir}/{o}\")\n",
        "if __name__ == \"__main__\":\n",
        "    download_df()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting download_df.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7nGrqfdV9u0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "777d9114-3198-4c76-e0c0-9eecc97163cd"
      },
      "source": [
        "try:\n",
        "  !mkdir ~/.kaggle\n",
        "except:\n",
        "  pass\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "api_token = {\"username\": \"jdsz5paulina\", \"key\": \"5277445bf2e6cef9aac564d8f7c5b87d\"}\n",
        "import json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydM43ripXFr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "966d4604-5d8b-438f-ad77-c21ce593de75"
      },
      "source": [
        "!python download_df.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.com: authenticated\n",
            "Downloading asl-alphabet.zip to data\n",
            " 99% 1.02G/1.03G [00:05<00:00, 213MB/s]\n",
            "100% 1.03G/1.03G [00:05<00:00, 197MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujhosZYYweEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = 'data/asl_alphabet_train/asl_alphabet_train'\n",
        "test_dir = \"data/asl_alphabet_test/asl_alphabet_test\"\n",
        "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
        "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
        "                   'Z':25,'space':26,'del':27,'nothing':28}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQtWqdPowIMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    print(\"LOADING DATA FROM : \",end = \"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        print(folder, end = ' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n",
        "            temp_img = cv2.resize(temp_img, size)\n",
        "            images.append(temp_img)\n",
        "            labels.append(labels_dict[folder])\n",
        "    \n",
        "    images = np.array(images)\n",
        "    images = images.astype('float32')/255.0\n",
        "    \n",
        "    labels = keras.utils.to_categorical(labels)\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)\n",
        "    print()\n",
        "    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n",
        "    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n",
        "    \n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7NBVuNsx-RY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(model, x, y, callbacks_list ,eps=5):\n",
        "    model_hist = model.fit(x, y, batch_size = 10, epochs = eps, validation_split = 0.1, callbacks=callbacks_list)\n",
        "    return model_hist "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-Clw6bgwOTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(pretrained_model, all_character_names, IMG_SIZE, show_summary=True):\n",
        "    IN_SHAPE = (*IMG_SIZE, 3)\n",
        "    if pretrained_model == 'VGG16':\n",
        "        pretrained_model = keras.applications.VGG16(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'ResNet152':\n",
        "        pretrained_model = keras.applications.ResNet152(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'InceptionV3':\n",
        "        pretrained_model = keras.applications.InceptionV3(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'DenseNet121':\n",
        "        pretrained_model = keras.applications.DenseNet121(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'NASNetLarge':\n",
        "        pretrained_model = keras.applications.NASNetLarge(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'EfficientNetB3':\n",
        "        pretrained_model = keras.applications.EfficientNetB3(\n",
        "            include_top=False,\n",
        "            input_shape=IN_SHAPE,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    elif pretrained_model == 'EfficientNetB7':\n",
        "        input = Input(shape=IN_SHAPE)\n",
        "        inception_model = keras.applications.EfficientNetB7(\n",
        "            include_top=False,\n",
        "            input_tensor=input,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "        \n",
        "        flattened_outputs = [Flatten()(inception_model.output),\n",
        "                             Flatten()(xception_model.output),\n",
        "                             Flatten()(resnet_model.output)]\n",
        "        output = Concatenate()(flattened_outputs)\n",
        "        pretrained_model = Model(input, output)\n",
        "    output = pretrained_model.output\n",
        "    # if pretrained_model.output.shape.ndims > 2:\n",
        "    #     output = Flatten()(output)\n",
        "    # else:\n",
        "    output = Flatten()(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Dropout(0.5)(output)\n",
        "    output = Dense(512, activation='relu')(output)\n",
        "        # output = BatchNormalization()(output)\n",
        "        # output = Dropout(0.5)(output)\n",
        "    output = Dense(all_character_names, activation='sigmoid')(output)\n",
        "    model = keras.models.Model(pretrained_model.input, output)\n",
        "    for layer in pretrained_model.layers:\n",
        "        layer.trainable = False\n",
        "    if show_summary:\n",
        "        model.summary(line_length=200)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Q0dkw0vTcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQj6TbLRlnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model, pat, name):\n",
        "  if not os.path.exists(pat):\n",
        "      os.makedirs(pat)\n",
        "  try:\n",
        "    model.save(f\"{pat}/{name}.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LyMxo0jryD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_charts(history, pat, name):\n",
        "  if not os.path.exists(pat):\n",
        "      os.makedirs(pat)\n",
        "  try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig(f\"{pat}/{name}.png\")\n",
        "    print(\"Saved chart to disk\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG1GtYQBaW-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil, pathlib, fnmatch\n",
        "\n",
        "def move_dir(src: str, dst: str, pattern: str = '*'):\n",
        "    if not os.path.isdir(dst):\n",
        "        pathlib.Path(dst).mkdir(parents=True, exist_ok=True)\n",
        "    for f in fnmatch.filter(os.listdir(src), pattern):\n",
        "        shutil.move(os.path.join(src, f), os.path.join(dst, f))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzWVWK64zOsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iter_models(pretrained_model_list):\n",
        "  for pm, size, epochs in pretrained_model_list:\n",
        "    try:\n",
        "      print(f\"fitting: {pm} in size: {size}\")\n",
        "      name = f\"model={pm}_size={size}_epochs={epochs}\"\n",
        "      disk_path = \"/content/gdrive/My Drive/dl_project\"\n",
        "      trained_model = Path(f\"{disk_path}/models/{pm}/{name}.h5\")\n",
        "\n",
        "      if not os.path.exists(f\"{disk_path}/models/{pm}\"):\n",
        "          os.makedirs(f\"{disk_path}/models/{pm}\")\n",
        "      if not os.path.exists(f\"{disk_path}/models/{pm}/logs\"):\n",
        "          os.makedirs(f\"{disk_path}/models/{pm}/logs\")\n",
        "      if trained_model.is_file():\n",
        "          continue\n",
        "\n",
        "      X_train, X_test, Y_train, Y_test = load_data(size=size)\n",
        "      mod = get_model(pm, 29, size, show_summary=False)\n",
        "      model_checkpoint_name = \"{epoch:02d}-{accuracy:.2f}.h5\"\n",
        "      checkpoint = ModelCheckpoint(f\"{disk_path}/models/{pm}/{pm}-{model_checkpoint_name}\", monitor='accuracy', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "      callbacks_list = [\n",
        "        checkpoint,\n",
        "        TensorBoard(log_dir=\"logs\"),\n",
        "      ]\n",
        "      history = fit_model(mod, X_train, Y_train, callbacks_list, eps=epochs)\n",
        "      save_model(mod, f\"{disk_path}/models/{pm}\", name)\n",
        "      save_charts(history, f\"{disk_path}/models/{pm}/charts\", name)\n",
        "      try:\n",
        "        move_dir(\"logs\", f\"{disk_path}/models/{pm}/logs\")\n",
        "        import gc\n",
        "        gc.collect()\n",
        "      except Exception as ex:\n",
        "        print(ex)\n",
        "    except Exception as e:\n",
        "      print(e)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sNIOYo0TTkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "9bb43a98-f1b7-4b9e-d27f-551a048ef2a4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 30 11:20:02 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PE1L9iML-3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1941b97e-cfe0-4d0a-dae7-390fcbef5b6b"
      },
      "source": [
        "  pretrained_model_list = [\n",
        "                           # ('VGG16', (71, 71), 12),\n",
        "                           # ('ResNet152', (71, 71), 12),\n",
        "                           # ('InceptionV3', (71, 71), 12),\n",
        "                           # ('DenseNet121', (71, 71), 12),\n",
        "                           ('NASNetLarge', (331, 331), 12)\n",
        "                           # ('EfficientNetB3', (71, 71), 12)\n",
        "                           # ('EfficientNetB7', (71, 71), 12)\n",
        "                           ]\n",
        "iter_models(pretrained_model_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting: NASNetLarge in size: (331, 331)\n",
            "LOADING DATA FROM : B | K | I | Y | M | R | E | Z | L | del | P | N | nothing | "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqGhv8Cd7cPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# brakuje RAMu"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}