{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrHousingModels = {\n",
    "    \"decision_tree\": DecisionTreeRegressor(),\n",
    "    \"random_forest\": RandomForestRegressor(),\n",
    "    \"xgboost\": XGBRegressor(objective=\"reg:squarederror\"),\n",
    "    \"svm\": SVR(),\n",
    "    \"knn\": KNeighborsRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrTinyDataSplit = (regrTinyX_train, regrTinyX_test, regrTinyY_train, regrTinyY_test) = train_test_split(regrTinyData.data, regrTinyData.target, test_size=testSize, random_state=randomState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja trenująca model\n",
    "def trainCV(model, data, target, cv=5):\n",
    "    \"\"\"\n",
    "    funkcja przeprowadzająca krosswalidację oraz zwracająca średnie wartości czasów i score'a\n",
    "    :param model: model estymatora z pakietu sklearn\n",
    "    :param data: cechy do przeprowadzenia uczenia\n",
    "    :param target: wartości wyjściowe\n",
    "    :param cv: ilość podziałów na krosswalidację, domyślnie 5\n",
    "    \"\"\"\n",
    "    # przeprowadzamy kross walidację i zbieramy wyniki\n",
    "    results = cross_validate(model, data, target, cv=cv)\n",
    "    # zwracamy średnie ze wszystkich przebiegów\n",
    "    outputDict = {\n",
    "        'meanFitTime': results['fit_time'].mean(),\n",
    "        'meanScoreTime': results['score_time'].mean(),\n",
    "        'meanScore':  results['test_score'].mean()\n",
    "    }\n",
    "    return outputDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResultsCharts(results, figsize=(15, 20)):\n",
    "    \"\"\"\n",
    "    Wyświetlanie wykresów wyników treningu\n",
    "    :param results: wyniki treningu w postaci słownika list, np. {\n",
    "        \"modelName\": [], <- ta lista musi być zawsze, reszta jest opcjonalna\n",
    "        \"meanScore\": [], \n",
    "        \"meanFitTime\": [],\n",
    "        \"meanScoreTime\": []}\n",
    "    \"\"\"\n",
    "    # pobieramy listę nazw zawartości\n",
    "    keys = list(results.keys())\n",
    "    \n",
    "    # tworzymy kontener na wykresy\n",
    "    axis_number = len(keys)-1\n",
    "    fig, axs = plt.subplots(axis_number, 1, figsize=figsize)\n",
    "    if axis_number > 1:\n",
    "        for i in range(axis_number):\n",
    "            axs[i].bar(results[keys[0]],results[keys[i+1]])\n",
    "            axs[i].set_ylabel(keys[i+1])\n",
    "            axs[i].set_title(keys[i+1])\n",
    "            axs[i].set_xlabel(keys[0])\n",
    "    else:\n",
    "        axs.bar(results[keys[0]],results[keys[1]])\n",
    "        axs.set_ylabel(keys[1])\n",
    "        axs.set_title(keys[1])\n",
    "        axs.set_xlabel(keys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainAndPrintResults(modelList, dataset, figsize=(15, 20)):\n",
    "    \"\"\"\n",
    "    funkcja przeprowadzająca trening na liście modeli.\n",
    "    :param modelList: Lista modeli kompatybilnych z pakietem sklearn\n",
    "    :param dataset: krotka datasetu po podziale na train i test w postaci (x_train, x_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    # bierzemy z datasetu dane treningowe\n",
    "    x_train, x_test, y_train, y_test = dataset\n",
    "    # pusty słownik na wyniki\n",
    "    results = {\n",
    "        \"modelName\": [],\n",
    "        \"meanScore\": [],\n",
    "        \"meanFitTime\": [],\n",
    "        \"meanScoreTime\": []\n",
    "    }\n",
    "    # lecimy po modelach i uczymy\n",
    "    for oneM in modelList:\n",
    "        tmpOneRes = trainCV(modelList[oneM], x_train, y_train)\n",
    "        print(\"{0} mean train score = {1}\".format(oneM,(tmpOneRes['meanScore'])))\n",
    "        results[\"modelName\"].append(oneM)\n",
    "        results[\"meanScore\"].append(tmpOneRes['meanScore'])\n",
    "        results[\"meanFitTime\"].append(tmpOneRes['meanFitTime'])\n",
    "        results[\"meanScoreTime\"].append(tmpOneRes['meanScoreTime'])\n",
    "        #finally fit on whole train data\n",
    "        modelList[oneM].fit(x_train, y_train)\n",
    "    \n",
    "    # present results on charts\n",
    "    printResultsCharts(results, figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrTinyResults = TrainAndPrintResults(regrTinyModels, regrTinyDataSplit)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestAndPrintResults(modelList, dataset, figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    funkcja przeprowadzająca trening na liście modeli.\n",
    "    :param modelList: Lista modeli kompatybilnych z pakietem sklearn\n",
    "    :param dataset: krotka datasetu po podziale na train i test w postaci (x_train, x_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    # bierzemy z datasetu dane treningowe\n",
    "    x_train, x_test, y_train, y_test = dataset\n",
    "    # pusty słownik na wyniki\n",
    "    results = {\n",
    "        \"modelName\": [],\n",
    "        \"testScore\": []\n",
    "    }\n",
    "    # lecimy po modelach i uczymy\n",
    "    for oneM in modelList:\n",
    "        testScore = modelList[oneM].score(x_test, y_test)\n",
    "        print(\"{0} score = {1}\".format(oneM,testScore))\n",
    "        results[\"modelName\"].append(oneM)\n",
    "        results[\"testScore\"].append(testScore)\n",
    "        \n",
    "    printResultsCharts(results, figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestAndPrintResults(regrTinyModels, regrTinyDataSplit, figsize=(15, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
